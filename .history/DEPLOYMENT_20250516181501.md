# Deployment Guide for App Longevity SaaS

This guide explains how to deploy the App Longevity SaaS application to various environments.

## Prerequisites

Before deployment, ensure you have:

- Python 3.8+ installed
- Node.js 14+ installed (for frontend)
- Docker and Docker Compose (optional)
- Git
- A database (SQLite for development, PostgreSQL recommended for production)

## Deployment Options

There are several ways to deploy this application:

1. **Local Development Setup**
2. **Docker Deployment**
3. **Cloud Platform Deployment**
   - Heroku
   - AWS Elastic Beanstalk
   - Google Cloud Run
   - Microsoft Azure App Service

## 1. Local Development Setup

### Backend Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/app_longevity_saas.git
cd app_longevity_saas

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
cd backend
pip install -r requirements.txt

# Start the server
python main.py
```

The backend will be available at http://localhost:8000

### Frontend Setup

```bash
# Navigate to the frontend directory
cd ../frontend

# Install dependencies
npm install

# Start the development server
npm run dev
```

The frontend will be available at http://localhost:3000

## 2. Docker Deployment

The project includes Docker configuration for easy deployment.

```bash
# Build and start the containers
docker-compose up -d

# To stop the containers
docker-compose down
```

The application will be accessible at:
- Backend: http://localhost:8000
- Frontend: http://localhost:3000

### Customizing Docker Environment

You can customize the environment variables in the `docker-compose.yml` file:

```yaml
environment:
  - DATABASE_URL=your_database_url
  - SECRET_KEY=your_secret_key
  - DEFAULT_MODEL=your_model_file.joblib
  - ADDITIONAL_MODEL_PATHS=additional/path
```

## 3. Cloud Platform Deployment

### Heroku Deployment

1. **Create a Heroku account and install the Heroku CLI**

2. **Login to Heroku**
   ```bash
   heroku login
   ```

3. **Create a Heroku app**
   ```bash
   heroku create app-longevity-saas
   ```

4. **Add a Postgres database**
   ```bash
   heroku addons:create heroku-postgresql:hobby-dev
   ```

5. **Configure environment variables**
   ```bash
   heroku config:set SECRET_KEY=your_production_secret_key
   heroku config:set DEFAULT_MODEL=rf_model.joblib
   ```

6. **Deploy the application**
   ```bash
   git push heroku main
   ```

7. **Run database migrations**
   ```bash
   heroku run python -m backend.core.database
   ```

### AWS Elastic Beanstalk Deployment

1. **Install the AWS EB CLI**
   ```bash
   pip install awsebcli
   ```

2. **Initialize EB application**
   ```bash
   eb init -p python-3.8 app-longevity-saas
   ```

3. **Create an environment**
   ```bash
   eb create app-longevity-production
   ```

4. **Configure environment variables**
   Go to AWS Management Console > Elastic Beanstalk > Your Application > Configuration > Software > Environment properties and add:
   - SECRET_KEY
   - DATABASE_URL
   - DEFAULT_MODEL

5. **Deploy the application**
   ```bash
   eb deploy
   ```

### Google Cloud Run Deployment

1. **Install Google Cloud SDK**

2. **Initialize gcloud**
   ```bash
   gcloud init
   ```

3. **Build the Docker image**
   ```bash
   gcloud builds submit --tag gcr.io/your-project/app-longevity-saas
   ```

4. **Deploy to Cloud Run**
   ```bash
   gcloud run deploy app-longevity-saas \
     --image gcr.io/your-project/app-longevity-saas \
     --platform managed \
     --set-env-vars="SECRET_KEY=your_production_secret_key,DEFAULT_MODEL=rf_model.joblib"
   ```

## Environment Variables

| Variable | Description | Example |
|----------|-------------|---------|
| SECRET_KEY | Secret key for JWT tokens | "mysecretkey123" |
| DATABASE_URL | Database connection string | "postgresql://user:password@localhost/dbname" |
| DEFAULT_MODEL | Default model file to use | "rf_model.joblib" |
| ADDITIONAL_MODEL_PATHS | Additional model paths | "path1,path2" |
| HOST | Host to run the server on | "0.0.0.0" |
| PORT | Port to run the server on | "8000" |

## Database Setup

The application will automatically create the database tables on first run. For production, it's recommended to use a PostgreSQL database. You can also run migrations manually:

```bash
python -c "from backend.core.database import Base, engine; Base.metadata.create_all(engine)"
```

## Handling Machine Learning Models

Ensure your model files are available in one of these locations:
1. In the `backend/static/models/` directory
2. In a directory specified in the `ADDITIONAL_MODEL_PATHS` environment variable

For cloud deployments, you may need to upload your model files to a cloud storage service and modify the `ModelManager` to download them on startup.

## Production Considerations

1. **Use a production WSGI server**:
   ```bash
   # Install gunicorn
   pip install gunicorn
   
   # Run with gunicorn
   cd backend
   gunicorn -w 4 -k uvicorn.workers.UvicornWorker main:app
   ```

2. **Set up SSL/TLS**:
   Use a reverse proxy like Nginx or deploy on a platform that provides SSL termination.

3. **Configure a production database**:
   Use a managed database service with proper scaling and backup policies.

4. **Set up monitoring**:
   Consider adding monitoring and logging solutions like Prometheus, Grafana, or ELK stack.

5. **CI/CD Pipeline**:
   Set up automated testing and deployment using GitHub Actions, GitLab CI, or similar tools.

## Troubleshooting

### Common Issues

#### Model Loading Failures
- Check that model files exist in the expected locations
- Ensure model file format matches the extension (.joblib, .pkl, etc.)
- Verify that all dependencies for the model are installed

#### Database Connection Issues
- Confirm database URL is correct
- Ensure database server is running
- Check network connectivity to the database

#### Missing Dependencies
- Ensure all dependencies are installed with `pip install -r requirements.txt`
- Check for OS-specific dependencies that might be missing

## Scaling the Application

To handle increased load:

1. **Use load balancing**:
   Deploy multiple instances behind a load balancer.

2. **Scale the database**:
   Move to a managed database service that can scale.

3. **Implement caching**:
   Add Redis or another caching solution for frequently accessed data.

4. **Optimize model inference**:
   Consider model quantization or serving via specialized tools like TensorFlow Serving.

## Backup and Recovery

1. **Database Backups**:
   Set up regular database backups.

2. **Model Version Control**:
   Keep versions of your ML models and their metadata.

3. **Application Code**:
   Use Git for version control and keep multiple backups.

4. **Disaster Recovery Plan**:
   Document steps to recover the application in case of failure.

## Security Considerations

1. **Keep secrets secure**:
   Never commit secrets to version control. Use environment variables or a secrets management service.

2. **Implement proper authentication**:
   The app has JWT authentication, but consider adding MFA for admin access.

3. **Regular updates**:
   Keep dependencies updated to avoid security vulnerabilities.

4. **API rate limiting**:
   Implement rate limiting to prevent abuse. 
